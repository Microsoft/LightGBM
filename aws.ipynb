{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use `lightgbm.dask` to train a LightGBM model on data stored as a [Dask DataFrame](https://docs.dask.org/en/latest/dataframe.html) or [Dask Array](https://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "It uses `FargateCluster` from [`dask-cloudprovider`](https://github.com/dask/dask-cloudprovider) to create a distributed cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up a cluster on AWS Fargate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler and worker image: public.ecr.aws/m0z8a6o8/dask-lgb-test-66d8e7ff-3c48-426c-993b-6bdf1243f916-cluster:1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ecr-details.json\", \"r\") as f:\n",
    "    ecr_details = json.loads(f.read())\n",
    "\n",
    "CONTAINER_IMAGE = ecr_details[\"repository\"][\"repositoryUri\"] + \":1\"\n",
    "print(f\"scheduler and worker image: {CONTAINER_IMAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, set up your AWS credentials. If you're unsure how to do this, see [the AWS docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cluster with 3 workers. See https://cloudprovider.dask.org/en/latest/aws.html#dask_cloudprovider.aws.FargateCluster for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/contextlib.py:120: UserWarning: Creating your cluster is taking a surprisingly long time. This is likely due to pending resources on AWS. Hang tight! \n",
      "  next(self.gen)\n",
      "/opt/conda/lib/python3.8/site-packages/distributed/client.py:1128: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+---------------+---------------+---------------+\n",
      "| Package | client        | scheduler     | workers       |\n",
      "+---------+---------------+---------------+---------------+\n",
      "| blosc   | 1.10.1        | 1.9.2         | 1.9.2         |\n",
      "| msgpack | 1.0.2         | 1.0.0         | 1.0.0         |\n",
      "| numpy   | 1.19.5        | 1.18.5        | 1.18.5        |\n",
      "| python  | 3.8.5.final.0 | 3.8.0.final.0 | 3.8.0.final.0 |\n",
      "| tornado | 6.0.4         | 6.1           | 6.1           |\n",
      "+---------+---------------+---------------+---------------+\n",
      "Notes: \n",
      "-  msgpack: Variation is ok, as long as everything is above 0.6\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "from dask_cloudprovider.aws import FargateCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "n_workers = 3\n",
    "cluster = FargateCluster(\n",
    "    image=CONTAINER_IMAGE,\n",
    "    worker_cpu=512,\n",
    "    worker_mem=4096,\n",
    "    n_workers=n_workers,\n",
    "    fargate_use_private_ip=False,\n",
    "    scheduler_timeout=\"40 minutes\",\n",
    "    find_address_timeout=60 * 10,\n",
    ")\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the dashboard: http://54.203.139.62:8787/status\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link above to view a diagnostic dashboard while you run the training code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.distributed import wait\n",
    "from lightgbm.dask import DaskLGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt 0\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:35941': 12400, 'tcp://172.31.49.205:42975': 12401, 'tcp://172.31.57.243:37337': 12402}\n",
      "attempt 1\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:40295': 12400, 'tcp://172.31.49.205:37995': 12402, 'tcp://172.31.57.243:38989': 12401}\n",
      "attempt 2\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.57.243:46333': 12400, 'tcp://172.31.49.205:45193': 12402, 'tcp://172.31.4.117:36941': 12401}\n",
      "attempt 3\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:43961': 12400, 'tcp://172.31.49.205:33229': 12402, 'tcp://172.31.57.243:44241': 12403}\n",
      "attempt 4\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:34297': 12400, 'tcp://172.31.57.243:46027': 12402, 'tcp://172.31.49.205:41983': 12401}\n",
      "attempt 5\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:34703': 12400, 'tcp://172.31.57.243:40619': 12401, 'tcp://172.31.49.205:43009': 12402}\n",
      "attempt 6\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.57.243:33825': 12400, 'tcp://172.31.4.117:32845': 12401, 'tcp://172.31.49.205:41851': 12403}\n",
      "attempt 7\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:39325': 12400, 'tcp://172.31.49.205:33193': 12404, 'tcp://172.31.57.243:39039': 12401}\n",
      "attempt 8\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.4.117:46809': 12400, 'tcp://172.31.57.243:35043': 12402, 'tcp://172.31.49.205:38587': 12401}\n",
      "attempt 9\n",
      "worker_address_to_port\n",
      "{'tcp://172.31.49.205:36081': 12400, 'tcp://172.31.57.243:35169': 12403, 'tcp://172.31.4.117:38359': 12401}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"attempt {i}\")\n",
    "    \n",
    "    client.restart()\n",
    "\n",
    "    num_rows = 1e6\n",
    "    num_features = 1e2\n",
    "    num_partitions = 10\n",
    "    rows_per_chunk = num_rows / num_partitions\n",
    "\n",
    "    data = da.random.random((num_rows, num_features), (rows_per_chunk, num_features))\n",
    "\n",
    "    labels = da.random.random((num_rows, 1), (rows_per_chunk, 1))\n",
    "\n",
    "    data = data.persist()\n",
    "    labels = labels.persist()\n",
    "    _ = wait(data)\n",
    "    _ = wait(labels)\n",
    "\n",
    "    dask_reg = DaskLGBMRegressor(\n",
    "        silent=False,\n",
    "        max_depth=5,\n",
    "        random_state=708,\n",
    "        objective=\"regression_l2\",\n",
    "        learning_rate=0.1,\n",
    "        tree_learner=\"data\",\n",
    "        n_estimators=10,\n",
    "        min_child_samples=1,\n",
    "        n_jobs=-1,\n",
    "        local_listen_port=12400,\n",
    "    )\n",
    "\n",
    "    dask_reg.fit(\n",
    "        client=client,\n",
    "        X=data,\n",
    "        y=labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model produced by this training run is an instance of `DaskLGBMRegressor`. To get a regular non-Dask model (which can be pickled and saved), run `.to_local()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = dask_reg.to_local()\n",
    "type(local_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize this model by looking at a data frame representation of it. You can also check that the model really used inputs from all workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_reg.booster_.trees_to_dataframe().iloc[0,][\"count\"] == 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
